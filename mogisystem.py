import os
import warnings
from typing import List, Dict, Optional
import anthropic
import google.generativeai as genai
from openai import OpenAI
import time
import dotenv
from dataclasses import dataclass
from enum import Enum

@dataclass
class AIResponse:
    content: str
    error: Optional[str] = None

class AIModel(Enum):
    GPT = "gpt"
    CLAUDE = "claude"
    GEMINI = "gemini"

class MAGISystem:
    def __init__(self):
        dotenv.load_dotenv()
        self._initialize_clients()
        self._initialize_roles()

    def _initialize_clients(self) -> None:
        """APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–"""
        try:
            # OpenAI
            self.openai_client = OpenAI(api_key=self._get_env_var("OPENAI_API_KEY"))
            self.openai_model = self._get_env_var("OPENAI_MODEL", default="gpt-4")
            
            # Anthropic
            self.anthropic_client = anthropic.Anthropic(api_key=self._get_env_var("ANTHROPIC_API_KEY"))
            self.anthropic_model = self._get_env_var("ANTHROPIC_MODEL", default="claude-3-opus-20240229")
            
            # Google
            genai.configure(api_key=self._get_env_var("GOOGLE_API_KEY"))
            self.gemini_model = self._get_env_var("GEMINI_MODEL", default="gemini-pro")
            self.gemini = genai.GenerativeModel(self.gemini_model)
        except Exception as e:
            raise RuntimeError(f"ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")

    def _get_env_var(self, key: str, default: Optional[str] = None) -> str:
        """ç’°å¢ƒå¤‰æ•°ã®å–å¾—ã¨æ¤œè¨¼"""
        value = os.getenv(key, default)
        if value is None:
            raise ValueError(f"ç’°å¢ƒå¤‰æ•° {key} ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return value

    def _initialize_roles(self) -> None:
        """AIå½¹å‰²ã®å®šç¾©"""
        self.roles = {
            AIModel.GPT: "ã‚ãªãŸã¯è«–ç†çš„ãªåˆ†æã¨æ‰¹åˆ¤çš„æ€ã‚’å¾—æ„ã¨ã™ã‚‹è­°è«–è€…ã§ã™ã€‚",
            AIModel.CLAUDE: "ã‚ãªãŸã¯å¹…åºƒã„çŸ¥è­˜ã¨å‰µé€ çš„ãªç™ºæƒ³ã‚’æŒã¤è­°è«–è€…ã§ã™ã€‚",
            AIModel.GEMINI: "ã‚ãªãŸã¯å®Ÿè·µçš„ã§ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸè¦–ç‚¹ã‚’æŒã¤è­°è«–è€…ã§ã™ã€‚"
        }

    def get_ai_response(self, model: AIModel, prompt: str) -> AIResponse:
        """çµ±ä¸€ã•ã‚ŒãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§AIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—"""
        try:
            if model == AIModel.GPT:
                return self._get_gpt_response(prompt)
            elif model == AIModel.CLAUDE:
                return self._get_claude_response(prompt)
            elif model == AIModel.GEMINI:
                return self._get_gemini_response(prompt)
        except Exception as e:
            return AIResponse(content="", error=str(e))

    def _get_gpt_response(self, prompt: str) -> AIResponse:
        """GPT-4ã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—"""
        response = self.openai_client.chat.completions.create(
            model=self.openai_model,
            messages=[
                {"role": "system", "content": self.roles[AIModel.GPT]},
                {"role": "user", "content": prompt}
            ],
            stream=True
        )
        
        full_response = ""
        print(f"\nğŸ”µ {self.openai_model}ã®è¦–ç‚¹:")
        for chunk in response:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                print(content, end="", flush=True)
                full_response += content
        print()
        return AIResponse(content=full_response)

    def _get_claude_response(self, prompt: str) -> AIResponse:
        """Claudeã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—"""
        response = self.anthropic_client.messages.create(
            model=self.anthropic_model,
            max_tokens=1000,
            system=self.roles[AIModel.CLAUDE],
            messages=[{"role": "user", "content": prompt}],
            stream=True
        )
        
        full_response = ""
        print(f"\nğŸŸ£ {self.anthropic_model}ã®è¦–ç‚¹:")
        for message in response:
            if message.type == "content_block_delta":
                content = message.delta.text
                print(content, end="", flush=True)
                full_response += content
        print()
        return AIResponse(content=full_response)

    def _get_gemini_response(self, prompt: str) -> AIResponse:
        """Geminiã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—"""
        try:
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                response = self.gemini.generate_content(
                    f"{self.roles[AIModel.GEMINI]}\n\n{prompt}",
                    safety_settings={"HARM_CATEGORY_HARASSMENT": "BLOCK_NONE"},
                    generation_config={
                        "temperature": 0.7,
                        "top_p": 0.8,
                        "top_k": 40
                    },
                    stream=True
                )
            
            full_response = ""
            print(f"\nğŸŸ¢ {self.gemini_model}ã®è¦–ç‚¹:")
            for chunk in response:
                if chunk.text:
                    print(chunk.text, end="", flush=True)
                    full_response += chunk.text
            print()
            return AIResponse(content=full_response)
            
        except Exception as e:
            return AIResponse(content="", error=f"Geminiã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {str(e)}")

    def _generate_conclusion(self, discussion_history: List[Dict]) -> Dict:
        """æœ€çµ‚çµè«–ã‚’ç”Ÿæˆ"""
        try:
            conclusion_prompt = f"""
            ã“ã‚Œã¾ã§ã®è­°è«–å…¨ä½“ã‚’è¸ã¾ãˆã¦ã€æœ€çµ‚çš„ãªçµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ã€‚
            ä»¥ä¸‹ãŒè­°è«–ã®å±¥æ­´ã§ã™ï¼š{discussion_history}
            """
            conclusion = self.get_ai_response(AIModel.CLAUDE, conclusion_prompt)
            return {
                "discussion_history": discussion_history,
                "final_conclusion": conclusion.content
            }
        except Exception as e:
            print(f"\n### âš ï¸ çµè«–ã®å°å‡ºæ™‚ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            return {
                "discussion_history": discussion_history,
                "final_conclusion": "çµè«–ã®å°å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚"
            }

    def facilitate_discussion(self, topic: str, rounds: int = 3) -> Dict:
        """AIã«ã‚ˆã‚‹è­°è«–ã‚’é€²è¡Œ"""
        discussion_history = []
        current_prompt = topic

        for round_num in range(rounds):
            print(f"\n## ğŸ¤– ãƒ©ã‚¦ãƒ³ãƒ‰ {round_num + 1}")
            
            try:
                responses = self._get_round_responses(current_prompt)
                discussion_history.append({
                    "round": round_num + 1,
                    **responses
                })
                current_prompt = self._prepare_next_prompt(responses)
                print("\n---")
                time.sleep(2)

            except Exception as e:
                print(f"\n### âš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                continue

        # æœ€çµ‚çµè«–ã®ç”Ÿæˆ
        conclusion_prompt = f"""
        ã“ã‚Œã¾ã§ã®è­°è«–ã‚’ç·æ‹¬ã—ã€ä»¥ä¸‹ã®ç‚¹ã‚’å«ã‚ãŸç‹¬è‡ªã®çµè«–ã‚’å°ãå‡ºã—ã¦ãã ã•ã„ï¼š
        1. ã“ã‚Œã¾ã§ã®è­°è«–ã§è¦‹è½ã¨ã•ã‚Œã¦ã„ãŸè¦–ç‚¹
        2. å„AIã®æ„è¦‹ã®ä¸­ã§ç‰¹ã«é‡è¦ã ã¨æ€ã‚ã‚Œã‚‹ãƒã‚¤ãƒ³ãƒˆ
        3. ä»Šå¾Œã®å±•æœ›ã‚„æè¨€

        â€»ã“ã‚Œã¾ã§ã®ç™ºè¨€ã‚’å˜ã«è¦ç´„ã™ã‚‹ã®ã§ã¯ãªãã€æ–°ã—ã„è¦–ç‚¹ã§åˆ†æã—ã¦ãã ã•ã„ã€‚
        â€»ä»¥ä¸‹ãŒè­°è«–ã®å±¥æ­´ã§ã™ï¼š
        {discussion_history}
        """
        
        try:
            conclusion = self.get_ai_response(AIModel.CLAUDE, conclusion_prompt)
            return {
                "discussion_history": discussion_history,
                "final_conclusion": conclusion.content
            }
        except Exception as e:
            return {
                "discussion_history": discussion_history,
                "final_conclusion": f"çµè«–ã®å°å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}"
            }

    def _get_round_responses(self, prompt: str) -> Dict[str, str]:
        """1ãƒ©ã‚¦ãƒ³ãƒ‰ã®å¿œç­”ã‚’å–å¾—"""
        responses = {}
        
        # GPTã®å¿œç­”
        gpt_response = self.get_ai_response(AIModel.GPT, prompt)
        responses["gpt"] = gpt_response.content

        # Claudeã®å¿œç­”
        claude_prompt = f"{prompt}\n\nGPT-4ã®æ„è¦‹: {gpt_response.content}"
        claude_response = self.get_ai_response(AIModel.CLAUDE, claude_prompt)
        responses["claude"] = claude_response.content

        # Geminiã®å¿œç­”
        gemini_prompt = f"{claude_prompt}\nClaudeã®æ„è¦‹: {claude_response.content}"
        gemini_response = self.get_ai_response(AIModel.GEMINI, gemini_prompt)
        responses["gemini"] = gemini_response.content

        return responses

    def _prepare_next_prompt(self, responses: Dict[str, str]) -> str:
        """æ¬¡ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
        return f"""
        ã“ã‚Œã¾ã§ã®è­°è«–ã‚’è¸ã¾ãˆã¦ã€ã•ã‚‰ãªã‚‹æ¤œè¨ç‚¹ã‚„æ–°ã—ã„è¦–ç‚¹ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚

        è­°è«–ã®çµŒç·¯:
        GPT: {responses["gpt"]}
        Claude: {responses["claude"]}
        Gemini: {responses["gemini"]}
        """

def display_ascii_art():
    """ASCIIã‚¢ãƒ¼ãƒˆã‚’è¡¨ç¤º"""
    ascii_art = """
    â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ•”â•â•â•â•â•â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â•â•
    â–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
    â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ•â•â•â•â•â•šâ•â•â•â•â–ˆâ–ˆâ•‘  â•šâ–ˆâ–ˆâ•”â•  â•šâ•â•â•â•â–ˆâ–ˆâ•‘
    â–ˆâ–ˆâ•‘ â•šâ•â• â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘
    â•šâ•â•     â•šâ•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•      â•šâ•â•â•â•â•â•â•   â•šâ•â•   â•šâ•â•â•â•â•â•â•
    ============= MOGI-SYSTEM: Multi-AI Generative Intelligence System =============
    """
    print(ascii_art)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        display_ascii_art()
        magi = MAGISystem()

        print("\nğŸ’­ è­°è«–ã®ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")
        user_topic = input().strip()
        
        topic = f"""
        ãƒ†ãƒ¼ãƒï¼šã€Œ{user_topic}ã€
        
        ã“ã®ãƒ†ãƒ¼ãƒã«ã¤ã„ã¦ã€ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰è­°è«–ã‚’å±•é–‹ã—ã€
        å…·ä½“çš„ãªä¾‹ã‚’æŒ™ã’ãªãŒã‚‰æ¤œè¨ã—ã¦ãã ã•ã„ã€‚
        """

        # è­°è«–ã‚’é–‹å§‹
        result = magi.facilitate_discussion(topic)

        # çµæœã®å‡ºåŠ›
        print("\n=== æœ€çµ‚çµè«– ===")
        print(result["final_conclusion"])
        
    except Exception as e:
        print(f"\nâš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        return 1

    return 0

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)